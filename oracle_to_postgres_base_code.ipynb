{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "\n",
    "from pyspark import SparkContext, SparkConf,SQLContext,HiveContext\n",
    "\n",
    "from pyspark.sql import SparkSession,DataFrame,Column,Row,GroupedData,DataFrameNaFunctions\n",
    "from pyspark.sql.functions import lit,concat,col,concat_ws\n",
    "from pyspark.sql import functions as sf\n",
    "#from pyspark.sql import functions as sf\n",
    "\n",
    "\n",
    "\n",
    "#from local_lib.PSPARK_DF_245 import selectExpr\n",
    "\n",
    "import argparse\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sched, time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try: \n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName(\"PY_DFF\").setMaster(\"local[*]\").set(\"spark.executor.memory\", \"4g\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"SPARK_APPP\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "hc = HiveContext(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars ./ojdbc7.jar pyspark-shell'\n",
    "sc = spark.sparkContext.addPyFile(\"./ojdbc7.jar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize the variables \n",
    "ip = 'aiorc.cqgrwtaxaib2.us-east-1.rds.amazonaws.com'         ## host of the oracle RDS instance\n",
    "port = 1521                                                  ## port of the oracle RDS instance\n",
    "SID = 'ORCL'                                                ## Database of the oracle RDS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'B4B4KE4'\n",
    "password = 'AI64732661(('\n",
    "Data_table=\"IRIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "JdbcOracleUrl = 'jdbc:oracle:thin:{USER_NAME}/{PASSWORD}@//{URL}:{PORT}/{SID}'.format(USER_NAME=username,PASSWORD=password,URL=ip,PORT=port,SID=SID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLEDF = spark.read.format(\"jdbc\").option(\"url\",JdbcOracleUrl)\\\n",
    "            .option(\"dbtable\",Data_table).option(\"user\",username)\\\n",
    "            .option(\"password\",password)\\\n",
    "            .option(\"driver\",\"oracle.jdbc.driver.OracleDriver\")\\\n",
    "            .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|SEPAL_LENGTH|SEPAL_WIDTH|PETAL_LENGTH|PETAL_WIDTH|VARIETY|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| Setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| Setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| Setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TABLEDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Postgres_HOST = 'aipost1.cqgrwtaxaib2.us-east-1.rds.amazonaws.com'\n",
    "Postgres_Port = '5432'\n",
    "Postgres_DB = 'postgres'\n",
    "Postgres_TableName = 'IRIS'\n",
    "Postgres_User_Name = 'B4B4KE4'\n",
    "Postgres_User_Password = 'AI64732661(('\n",
    "\n",
    "Postgres_Driver_Name = 'org.postgresql.Driver'\n",
    "JdbcPostgresUrl = 'jdbc:postgresql://{HOST}:{PORT}/{DB}'.format(HOST=Postgres_HOST,PORT=Postgres_Port,DB=Postgres_DB)\n",
    "TABLEDF.write.jdbc(\n",
    "                url=JdbcPostgresUrl, \n",
    "                table=Postgres_TableName, \n",
    "                mode=\"overwrite\", \n",
    "                properties={\n",
    "                    \"user\":Postgres_User_Name, \n",
    "                    \"password\":Postgres_User_Password, \n",
    "                    \"driver\":Postgres_Driver_Name, \n",
    "                    \"client_encoding\":\"utf8\"\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Postgres_TABLEDF = spark.read.format(\"jdbc\").option(\"url\",JdbcPostgresUrl)\\\n",
    "            .option(\"dbtable\",Postgres_TableName).option(\"user\",Postgres_User_Name)\\\n",
    "            .option(\"password\",Postgres_User_Password)\\\n",
    "            .option(\"driver\",Postgres_Driver_Name)\\\n",
    "            .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|SEPAL_LENGTH|SEPAL_WIDTH|PETAL_LENGTH|PETAL_WIDTH|VARIETY|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| Setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| Setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| Setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Postgres_TABLEDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
